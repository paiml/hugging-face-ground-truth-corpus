"""Deployment recipes for HuggingFace models.

This module provides utilities for model quantization,
format conversion, and serving.

Examples:
    >>> from hf_gtc.deployment import ServerConfig, QuantizationType
    >>> config = ServerConfig(port=8080)
    >>> config.port
    8080
"""

from __future__ import annotations

from hf_gtc.deployment.compression import (
    VALID_DECOMPOSITION_METHODS,
    VALID_FUSION_TYPES,
    VALID_IMPORTANCE_METRICS,
    VALID_PRUNING_METHODS,
    VALID_PRUNING_SCOPES,
    VALID_STRUCTURED_DIMS,
    CompressionConfig,
    CompressionStats,
    DecompositionMethod,
    FusionType,
    ImportanceMetric,
    LayerFusionConfig,
    LowRankConfig,
    PruningConfig,
    PruningMethod,
    PruningSchedule,
    PruningScope,
    StructuredPruningConfig,
    StructuredPruningDim,
    WeightSharingConfig,
    calculate_flops_reduction,
    calculate_low_rank_params,
    calculate_sparsity_at_step,
    calculate_weight_sharing_bits,
    create_compression_config,
    create_compression_stats,
    create_layer_fusion_config,
    create_low_rank_config,
    create_pruning_config,
    create_pruning_schedule,
    create_structured_pruning_config,
    create_weight_sharing_config,
    estimate_compressed_size,
    estimate_speedup_from_sparsity,
    format_compression_stats,
    get_decomposition_method,
    get_fusion_type,
    get_importance_metric,
    get_pruning_method,
    get_pruning_scope,
    get_recommended_compression_config,
    get_structured_pruning_dim,
    list_decomposition_methods,
    list_fusion_types,
    list_importance_metrics,
    list_pruning_methods,
    list_pruning_scopes,
    list_structured_pruning_dims,
    validate_compression_config,
    validate_low_rank_config,
    validate_pruning_config,
    validate_structured_pruning_config,
    validate_weight_sharing_config,
)
from hf_gtc.deployment.gguf import (
    GGUFArchitecture,
    GGUFConfig,
    GGUFEndian,
    GGUFExportResult,
    GGUFMetadata,
    GGUFModelInfo,
    GGUFQuantType,
    create_gguf_config,
    create_gguf_export_result,
    create_gguf_metadata,
    estimate_gguf_size,
    format_gguf_export_result,
    format_gguf_model_info,
    get_gguf_architecture,
    get_gguf_config_dict,
    get_gguf_filename,
    get_gguf_metadata_dict,
    get_gguf_quant_type,
    get_recommended_gguf_quant,
    list_gguf_architectures,
    list_gguf_quant_types,
    validate_gguf_architecture,
    validate_gguf_config,
    validate_gguf_metadata,
    validate_gguf_quant_type,
)
from hf_gtc.deployment.merging import (
    DENSITY_VALUES,
    VALID_MERGE_METHODS,
    DensityType,
    MergeConfig,
    MergeMethod,
    MergeResult,
    ModelSlice,
    calculate_merged_parameter_count,
    create_merge_config,
    create_model_slice,
    estimate_merge_time,
    get_density_value,
    get_recommended_method,
    linear_interpolate,
    list_merge_methods,
    slerp,
    validate_merge_config,
    validate_model_slice,
)
from hf_gtc.deployment.onnx import (
    VALID_EXECUTION_PROVIDERS,
    VALID_ONNX_OPSET_VERSIONS,
    VALID_OPTIMIZATION_LEVELS,
    ExecutionProvider,
    ExportStats,
    ONNXExportConfig,
    ONNXModelInfo,
    ONNXOpset,
    ONNXOptimizeConfig,
    OptimizationLevel,
    RuntimeConfig,
    create_export_config,
    create_optimize_config,
    create_runtime_config,
    estimate_onnx_model_size,
    format_export_stats,
    format_model_info,
    get_execution_provider,
    get_export_config_dict,
    get_opset_version,
    get_optimization_level,
    get_recommended_opset,
    get_runtime_session_options,
    list_execution_providers,
    list_opset_versions,
    list_optimization_levels,
    validate_export_config,
    validate_runtime_config,
)
from hf_gtc.deployment.optimization import (
    OptimizationResult,
    QuantizationConfig,
    QuantizationType,
    calculate_compression_ratio,
    estimate_model_size,
    get_model_loading_kwargs,
    get_optimization_result,
    get_quantization_config,
    list_quantization_types,
)
from hf_gtc.deployment.quantization import (
    AWQConfig,
    CalibrationConfig,
    CalibrationMethod,
    GPTQConfig,
    QuantGranularity,
    QuantMethod,
    QuantProfile,
    QuantResult,
    compute_compression_ratio,
    create_awq_config,
    create_calibration_config,
    create_gptq_config,
    create_quant_profile,
    create_quant_result,
    estimate_quantized_size,
    format_quant_result,
    get_awq_dict,
    get_calibration_method,
    get_gptq_dict,
    get_quant_granularity,
    get_quant_method,
    get_recommended_profile,
    list_calibration_methods,
    list_quant_granularities,
    list_quant_methods,
    validate_calibration_config,
    validate_calibration_method,
    validate_quant_granularity,
    validate_quant_method,
    validate_quant_profile,
)
from hf_gtc.deployment.safetensors import (
    VALID_DTYPES,
    VALID_TENSOR_FORMATS,
    DType,
    FileInfo,
    LoadConfig,
    SaveConfig,
    TensorFormat,
    TensorInfo,
    calculate_memory_savings,
    create_load_config,
    create_metadata,
    create_save_config,
    estimate_file_size,
    format_size,
    get_recommended_dtype,
    list_dtypes,
    list_tensor_formats,
    validate_load_config,
    validate_save_config,
    validate_tensor_name,
)
from hf_gtc.deployment.serving import (
    HealthStatus,
    InferenceBackend,
    InferenceRequest,
    InferenceResponse,
    ModelServer,
    ServerConfig,
    ServerStatus,
    compute_server_metrics,
    create_server,
    format_server_info,
    get_health_status,
    get_inference_backend,
    get_server_status,
    list_inference_backends,
    list_server_statuses,
    process_batch,
    process_request,
    start_server,
    stop_server,
    validate_inference_backend,
    validate_server_config,
    validate_server_status,
)
from hf_gtc.deployment.torchscript import (
    CompilationStats,
    FreezeMode,
    MobileConfig,
    OptimizationConfig,
    OptimizeFor,
    ScriptMode,
    TorchScriptConfig,
    TorchScriptInfo,
    TraceConfig,
    check_scriptable,
    create_compilation_stats,
    create_mobile_config,
    create_optimization_config,
    create_torchscript_config,
    create_torchscript_info,
    create_trace_config,
    estimate_script_size,
    format_compilation_stats,
    format_torchscript_info,
    get_freeze_mode,
    get_mobile_config_dict,
    get_optimization_config_dict,
    get_optimize_for,
    get_recommended_config,
    get_script_mode,
    get_torchscript_config_dict,
    get_trace_config_dict,
    list_freeze_modes,
    list_optimize_for_options,
    list_script_modes,
    validate_mobile_config,
    validate_optimization_config,
    validate_torchscript_config,
    validate_trace_config,
)

__all__: list[str] = [
    # Constants
    "DENSITY_VALUES",
    "VALID_DECOMPOSITION_METHODS",
    "VALID_DTYPES",
    "VALID_EXECUTION_PROVIDERS",
    "VALID_FUSION_TYPES",
    "VALID_IMPORTANCE_METRICS",
    "VALID_MERGE_METHODS",
    "VALID_ONNX_OPSET_VERSIONS",
    "VALID_OPTIMIZATION_LEVELS",
    "VALID_PRUNING_METHODS",
    "VALID_PRUNING_SCOPES",
    "VALID_STRUCTURED_DIMS",
    "VALID_TENSOR_FORMATS",
    # Quantization
    "AWQConfig",
    "CalibrationConfig",
    "CalibrationMethod",
    # TorchScript
    "CompilationStats",
    # Compression
    "CompressionConfig",
    "CompressionStats",
    # SafeTensors
    "DType",
    "DecompositionMethod",
    "DensityType",
    # ONNX
    "ExecutionProvider",
    "ExportStats",
    "FileInfo",
    # TorchScript
    "FreezeMode",
    # Compression
    "FusionType",
    # GGUF
    "GGUFArchitecture",
    "GGUFConfig",
    "GGUFEndian",
    "GGUFExportResult",
    "GGUFMetadata",
    "GGUFModelInfo",
    "GGUFQuantType",
    "GPTQConfig",
    # Serving
    "HealthStatus",
    # Compression
    "ImportanceMetric",
    "InferenceBackend",
    "InferenceRequest",
    "InferenceResponse",
    # Compression
    "LayerFusionConfig",
    "LoadConfig",
    # Compression
    "LowRankConfig",
    "MergeConfig",
    "MergeMethod",
    "MergeResult",
    # TorchScript
    "MobileConfig",
    "ModelServer",
    "ModelSlice",
    # ONNX
    "ONNXExportConfig",
    "ONNXModelInfo",
    "ONNXOpset",
    "ONNXOptimizeConfig",
    # TorchScript
    "OptimizationConfig",
    # ONNX
    "OptimizationLevel",
    "OptimizationResult",
    # TorchScript
    "OptimizeFor",
    # Compression - Classes
    "PruningConfig",
    "PruningMethod",
    "PruningSchedule",
    "PruningScope",
    "QuantGranularity",
    "QuantMethod",
    "QuantProfile",
    "QuantResult",
    "QuantizationConfig",
    "QuantizationType",
    # ONNX
    "RuntimeConfig",
    "SaveConfig",
    # TorchScript
    "ScriptMode",
    "ServerConfig",
    "ServerStatus",
    "StructuredPruningConfig",
    "StructuredPruningDim",
    "TensorFormat",
    "TensorInfo",
    # TorchScript
    "TorchScriptConfig",
    "TorchScriptInfo",
    "TraceConfig",
    "WeightSharingConfig",
    # Functions - Quantization
    "calculate_compression_ratio",
    # Compression - Functions
    "calculate_flops_reduction",
    "calculate_low_rank_params",
    # Functions - SafeTensors
    "calculate_memory_savings",
    # Functions - Merging
    "calculate_merged_parameter_count",
    "calculate_sparsity_at_step",
    "calculate_weight_sharing_bits",
    # Functions - TorchScript
    "check_scriptable",
    "compute_compression_ratio",
    # Functions - Serving
    "compute_server_metrics",
    "create_awq_config",
    "create_calibration_config",
    # Functions - TorchScript
    "create_compilation_stats",
    "create_compression_config",
    "create_compression_stats",
    # Functions - ONNX
    "create_export_config",
    # Functions - GGUF
    "create_gguf_config",
    "create_gguf_export_result",
    "create_gguf_metadata",
    "create_gptq_config",
    "create_layer_fusion_config",
    "create_load_config",
    "create_low_rank_config",
    "create_merge_config",
    "create_metadata",
    # Functions - TorchScript
    "create_mobile_config",
    "create_model_slice",
    # Functions - TorchScript
    "create_optimization_config",
    # Functions - ONNX
    "create_optimize_config",
    "create_pruning_config",
    "create_pruning_schedule",
    "create_quant_profile",
    "create_quant_result",
    # Functions - ONNX
    "create_runtime_config",
    "create_save_config",
    "create_server",
    "create_structured_pruning_config",
    # Functions - TorchScript
    "create_torchscript_config",
    "create_torchscript_info",
    "create_trace_config",
    "create_weight_sharing_config",
    "estimate_compressed_size",
    "estimate_file_size",
    "estimate_gguf_size",
    "estimate_merge_time",
    "estimate_model_size",
    # Functions - ONNX
    "estimate_onnx_model_size",
    "estimate_quantized_size",
    # Functions - TorchScript
    "estimate_script_size",
    "estimate_speedup_from_sparsity",
    # Functions - TorchScript
    "format_compilation_stats",
    "format_compression_stats",
    # Functions - ONNX
    "format_export_stats",
    "format_gguf_export_result",
    "format_gguf_model_info",
    # Functions - ONNX
    "format_model_info",
    "format_quant_result",
    "format_server_info",
    "format_size",
    # Functions - TorchScript
    "format_torchscript_info",
    "get_awq_dict",
    "get_calibration_method",
    "get_decomposition_method",
    "get_density_value",
    # Functions - ONNX
    "get_execution_provider",
    # Functions - ONNX
    "get_export_config_dict",
    # Functions - TorchScript
    "get_freeze_mode",
    "get_fusion_type",
    "get_gguf_architecture",
    "get_gguf_config_dict",
    "get_gguf_filename",
    "get_gguf_metadata_dict",
    "get_gguf_quant_type",
    "get_gptq_dict",
    "get_health_status",
    "get_importance_metric",
    "get_inference_backend",
    # Functions - TorchScript
    "get_mobile_config_dict",
    "get_model_loading_kwargs",
    # Functions - ONNX
    "get_opset_version",
    # Functions - TorchScript
    "get_optimization_config_dict",
    # Functions - ONNX
    "get_optimization_level",
    "get_optimization_result",
    # Functions - TorchScript
    "get_optimize_for",
    "get_pruning_method",
    "get_pruning_scope",
    "get_quant_granularity",
    "get_quant_method",
    "get_quantization_config",
    "get_recommended_compression_config",
    # Functions - TorchScript
    "get_recommended_config",
    "get_recommended_dtype",
    "get_recommended_gguf_quant",
    "get_recommended_method",
    # Functions - ONNX
    "get_recommended_opset",
    "get_recommended_profile",
    # Functions - ONNX
    "get_runtime_session_options",
    # Functions - TorchScript
    "get_script_mode",
    "get_server_status",
    "get_structured_pruning_dim",
    # Functions - TorchScript
    "get_torchscript_config_dict",
    "get_trace_config_dict",
    "linear_interpolate",
    "list_calibration_methods",
    "list_decomposition_methods",
    "list_dtypes",
    # Functions - ONNX
    "list_execution_providers",
    # Functions - TorchScript
    "list_freeze_modes",
    "list_fusion_types",
    "list_gguf_architectures",
    "list_gguf_quant_types",
    "list_importance_metrics",
    "list_inference_backends",
    "list_merge_methods",
    # Functions - ONNX
    "list_opset_versions",
    # Functions - ONNX
    "list_optimization_levels",
    # Functions - TorchScript
    "list_optimize_for_options",
    "list_pruning_methods",
    "list_pruning_scopes",
    "list_quant_granularities",
    "list_quant_methods",
    "list_quantization_types",
    # Functions - TorchScript
    "list_script_modes",
    "list_server_statuses",
    "list_structured_pruning_dims",
    "list_tensor_formats",
    "process_batch",
    "process_request",
    "slerp",
    "start_server",
    "stop_server",
    "validate_calibration_config",
    "validate_calibration_method",
    "validate_compression_config",
    # Functions - ONNX
    "validate_export_config",
    "validate_gguf_architecture",
    "validate_gguf_config",
    "validate_gguf_metadata",
    "validate_gguf_quant_type",
    "validate_inference_backend",
    "validate_load_config",
    "validate_low_rank_config",
    "validate_merge_config",
    # Functions - TorchScript
    "validate_mobile_config",
    "validate_model_slice",
    # Functions - TorchScript
    "validate_optimization_config",
    "validate_pruning_config",
    "validate_quant_granularity",
    "validate_quant_method",
    "validate_quant_profile",
    # Functions - ONNX
    "validate_runtime_config",
    "validate_save_config",
    "validate_server_config",
    "validate_server_status",
    "validate_structured_pruning_config",
    "validate_tensor_name",
    # Functions - TorchScript
    "validate_torchscript_config",
    "validate_trace_config",
    "validate_weight_sharing_config",
]
